# 25.7.4

## 1.看了一篇论文 Corpus-Steered Query Expansion with Large Language Models

方法概述：

1.初筛文档：用 BM25 从语料库检索原始查询的前 10 篇文档（长文档截断至 128 tokens）。

2. 提取关键句：通过 LLM 的单样本提示（如 “识别相关文档并提取贡献相关性的句子”），从初筛文档中抽取事实性句子（83% 与原文完全一致）。
   
3. 生成假设扩展：LLM 针对原始查询生成假设性回答（如 “解释鲨鱼温血机制” 的段落），补充语义知识。
   
4. 融合扩展查询：将原始查询（重复 2 次）、语料库关键句、假设回答拼接，强化主题与事实性。

5. 二次检索：用融合后的查询再跑 BM25，输出最终结果。

## 2. 跑新idea实验，跑出来结果没基线好，打算重新换个思路去做，下个周打算将看的两篇论文缝合起来看看效果


# 25.6.27

## 1.完成数学建模一道题

## 2.看了一篇论文 QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion in Information Retrieval

## 3.正在mmlf这篇论文上加代码

# 25.6.20

## 1.复现了一篇论文，打算将这篇论文作为我的baseline，下一步思考在这篇论文的基础上创新，论文名（MMLF:Multi-query Multi-passage Late Fusion Retrieval），发表于naacl 2025

MMLF方法概述：

首先用大模型从原始查询分解出多个子查询（如针对“COVID-19治疗药物”生成“瑞德西韦疗效”“中药抗病毒作用”等子意图），接着将每个子查询扩展成独立段落（段落需同时回应原子查询和子查询），随后对原始查询和每个段落分别进行稠密检索，得到多个结果列表，最终通过排序融合算法（RRF）合并这些列表——即根据文档在不同列表中的排名计算加权得分，生成统一的排序结果。



## 2.读了一篇相同领域的论文

MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion

MILL方法流程总结​

​​1.输入​​：原始查询q

​​2.生成阶段​​：

生成N个子查询 $\{q_1,q_2,\ldots,q_N\}$ ​​每个子查询生成一个文档​​ $d_n^{LLM}$ （包含子查询+对应段落）  得到N个生成文档， $\mathcal{D}^{LLM}=\{d_1^{LLM},\ldots,d_N^{LLM}\}$

3.​​检索阶段​​：

用 BM25 检索原始查询 q，得到K个文档 $\mathcal{D}^{PRF}=\{d_1^{PRF},\ldots,d_K^{PRF}\}$

​​4.互验证：

构建N×K相似度矩阵（计算每个 $d_n^{LLM}$ 与 $d_k^{PRF}$ 的余弦相似度）

计算生成文档得分： $s_n^{LLM}=\sum_{k=1}^K\sin(d_n^{LLM},d_k^{PRF})$

计算检索文档得分： $s_k^{PRF}=\sum_{n=1}^N\sin(d_k^{PRF},d_n^{LLM})$

筛选： 取 $\mathrm{Top}_{N^{\prime}}$ 生成文档 $\mathcal{D}_s^{LLM}$ （高 $s_n^{LLM}$  值）

取 $\mathrm{Top}_{K^{\prime}}$ 检索文档 $\mathcal{D}_s^{PRF}$ （高 $s_k^{PRF}$ 值）

5.查询扩展​​：

构造新查询 

$\mid q^{\prime}=\underbrace{qqqqq}_{\text{原始查询重复5次}}\mathcal{D}_s^{PRF}\mathcal{D}_s^{LLM}$

6.最终检索​​：用 $q^{\prime}$ 执行稠密检索（如 ANCE、DPR）

# 25.6.13  

1.解决了上海项目的两个新需求

2.完成了数学建模的一道题

3.读了一篇文章：Mix-of-Granularity: Optimize the Chunking Granularity for Retrieval-Augmented Generation

笔记如下

# 方法

提出​​混合粒度方法：通过路由模块基于输入查询动态确定知识源的最优信息粒度。该路由模块采用软标签损失函数进行高效训练。我们进一步将MoG扩展为​​图混合粒度，将参考文档预处理为图结构，实现对分散文本片段的检索。

MOG

将知识库文档按n种粒度分块（如 n=5），其中粒度1为最细（如单句），粒度 j(j>=2)由粒度 j-1的 2 个相邻块合并而成，形成层级化分块结构。

对每个粒度下的片段，使用BM25算法计算与查询 q 的相似度分数，衡量语义相关性。

每个粒度提取前k个高相关片段（如 (k=3)），形成总大小为 n x k的候选片段池。

通过 RoBERTa 将查询 q 编码为向量，经路由器映射为权重向量w，维度与n一致，表征各粒度的重要性。

将各粒度下片段的 BM25 分数与 w 加权整合，突出最优粒度的片段相关性。

软标签构造（用于训练mlp）

对于每个查询 q，使用 BM25从每个粒度级别的参考文档中检索最相关的片段（S_best），然后通过静态模型（包括 TF-IDF、RoBERTa或命中率得分计算 S_best 中每个片段与标签 l 的语义相似度，并存储于 sim_best。我们为 S_best 中相似度最高（次高）的片段分配 0.8（0.2）的软标签，其余片段补 0。路由器通过最小化二元交叉熵损失函数进行训练

MoG 的两步选择策略：

第一步：从 最细粒度 中选 top-k 相关块（chunk_r，最细粒度的单元）；
第二步：找到 最优粒度g_r 中 包含chunk_r的块 ，作为最终检索结果。


MOGG

MoG 的局限：仅通过调整粒度处理相邻片段，无法有效应对复杂问题中分散在不同段落 / 文档的信息（如跨源推理需求）。

将文档拆分为 1-2 个句子的节点，基于 BM25 计算节点相似度，超过阈值 Tgraph 则连边，构建语义关联图。

延续 MoG 的多粒度路由框架，仅将分块逻辑从 “线性窗口” 改为 “图跳跃范围”，其余组件（如路由器、软标签训练）不变。




